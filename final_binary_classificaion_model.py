# -*- coding: utf-8 -*-
"""final_BC.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1PHIIfYUSpBwRgzw7OalXYNYXQ6P_j0jH
"""

from google.colab import files
files.upload()

import pandas as pd
import numpy as np

from google.colab import drive
drive.mount('/content/drive', force_remount=True)

#set path to the data we want to train
path = '/content/drive/Shareddrives/ECE 448 FA 2020-SP2021/449 (SP21)/Data/data (total shares)/amzn_edited.xlsx'

def fullScript(length,percent,incdec,path):
    df = pd.read_excel(path, index_col=0, usecols=[1,2,3,4], parse_dates=True)
    df['trading'] = df['Volume']/df['Shares Outstanding']
    SMA_12 = df.iloc[:, 0].rolling(12).mean()
    SMA_12.name = 'SMA 12 days'
    SMA_26 = df.iloc[:, 0].rolling(26).mean()
    SMA_26.name = 'SMA 26 days'
    EMA_12 = SMA_12.copy()
    EMA_12.iloc[11] = np.nan
    smoothing=0.074074074
    EMA_12.iloc[12] = smoothing * df.iloc[12, 0] + (1 - smoothing) * SMA_12.iloc[11]
    for i in range(13, len(EMA_12)):
        EMA_12.iloc[i] = smoothing * df.iloc[i, 0] + (1 - smoothing) * EMA_12.iloc[i-1]
    EMA_12.name = 'EMA 12 days'
    final = pd.concat([df, SMA_12, SMA_26, EMA_12], axis=1)
    ########################################################################
    final['new'] = 0
    final = final.to_numpy()
    start_index = length
    i = start_index
    z = len(final)-length
    

    if incdec == 1:
        for i in range(z):
            rowVector = final[i][:]
            TargetRV = final[i+length][:]
            if(rowVector[0] >= percent*TargetRV[0] + TargetRV[0]):
                rowVector[7] = 1
                final[i][:] = rowVector
            else:
                rowVector[7] = 0
                final[i][:] = rowVector
    else:
        for i in range(z):
            rowVector = final[i][:]
            TargetRV = final[i+length][:]
            if(rowVector[0] <= percent*TargetRV[0] + TargetRV[0]):
                rowVector[7] = 1
                final[i][:] = rowVector
            else:
                rowVector[7] = 0
                final[i][:] = rowVector

    df = pd.DataFrame(final)
    updatedDf = df
#     updatedDf = updatedDf.dropna()
    updatedDf = updatedDf.reset_index(drop=True)
    return updatedDf

prepped_data = fullScript(5,0.05,1,path)

def make_data(prepped_data):
    charecter = prepped_data.iloc[:,1:7]
    charecter.columns=['one','two','three','four','five','six']
    new_charecter = charecter.copy()
    new_charecter.columns=['before_one','before_two','before_three','before_four','before_five','before_six']
    df = pd.DataFrame(columns = ['before_one','before_two','before_three','before_four','before_five','before_six']) 
    df.loc[0] = [0,0,0,0,0,0]
    df_final = df.append(new_charecter)
    df_final = df_final.reset_index(drop=True)
    after_concat = pd.concat([charecter,df_final],axis=1)
    final_data = after_concat.dropna(axis=0,how='any') 
    final_data['check one']=final_data.apply(lambda x:x['one'] - x['before_one'],axis=1)
    final_data['check two']=final_data.apply(lambda x:x['two'] - x['before_two'],axis=1)
    final_data['check three']=final_data.apply(lambda x:x['three'] - x['before_three'],axis=1)
    final_data['check four']=final_data.apply(lambda x:x['four'] - x['before_four'],axis=1)
    final_data['check five']=final_data.apply(lambda x:x['five'] - x['before_five'],axis=1)
    final_data['check six']=final_data.apply(lambda x:x['six'] - x['before_six'],axis=1)
    final_data['P/N check one']=final_data.apply(lambda x: 1 if x['check one'] > 0 else 0,axis=1)
    final_data['P/N check two']=final_data.apply(lambda x: 1 if x['check two'] > 0 else 0,axis=1)
    final_data['P/N check three']=final_data.apply(lambda x: 1 if x['check three'] > 0 else 0,axis=1)
    final_data['P/N check four']=final_data.apply(lambda x: 1 if x['check four'] > 0 else 0,axis=1)
    final_data['P/N check five']=final_data.apply(lambda x: 1 if x['check five'] > 0 else 0,axis=1)
    final_data['P/N check six']=final_data.apply(lambda x: 1 if x['check six'] > 0 else 0,axis=1)
    final_data['analysis']=final_data.apply(lambda x:x['P/N check one'] + x['P/N check two'] + x['P/N check three'] 
                                        + x['P/N check four'] + x['P/N check five'] + x['P/N check six'],axis=1)
    final_data['N/X']=final_data.apply(lambda x: 1 if x['analysis'] > 3 else 0,axis=1)
    result = final_data[['one','two','three','four','five','six','N/X']]
    return result

after_add_NX = make_data(prepped_data)

after_add_NX

X = after_add_NX.iloc[:,:6]
y = after_add_NX['N/X']

from sklearn.model_selection import train_test_split

def train_test_val_split(df,ratio_train,ratio_test,ratio_val):
    train,middle = train_test_split(df,test_size=1-ratio_train)
    ratio=ratio_val/(1-ratio_train)
    test,validation =train_test_split(middle,test_size=ratio)
    return train,test,validation

x_train, x_test, x_val = train_test_val_split(X,0.8,0.1,0.1)
y_train, y_test, y_val = train_test_val_split(y,0.8,0.1,0.1)

import numpy as np

from keras import models
from keras import layers

model = models.Sequential()
model.add(layers.Dense(100,activation='relu',input_shape=(6,)))
model.add(layers.Dropout(0.3, name='lstm_dropout_0'))
model.add(layers.Dense(50,activation='relu'))
model.add(layers.Activation('sigmoid', name='sigmoid_0'))
model.add(layers.Dense(1,activation='sigmoid'))


from keras import optimizers

model.compile(optimizer=optimizers.RMSprop(lr=0.001), loss='binary_crossentropy', metrics=['accuracy'])


history = model.fit(x_train,y_train,epochs=10,batch_size=8)
history_dict = history.history

import matplotlib.pyplot as plt
acc = history_dict['accuracy']
loss_values = history_dict['loss']
epochs = range(1, len(loss_values) + 1)

plt.plot(epochs, acc, 'b', label='Training acc')
plt.title('Results')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()

plt.show()

# on test
test_loss,test_accuracy = model.evaluate(x_test,y_test)
print('\ntest loss : ',test_loss)
print('accuracy : ',test_accuracy)

# on val
val_loss,val_accuracy = model.evaluate(x_val,y_val)
print('\nval loss : ',val_loss)
print('accuracy : ',val_accuracy)

from sklearn.metrics import confusion_matrix, accuracy_score, classification_report
pred_dnn_train = model.predict(x_train).round()
print("Confusion Matrix: training data")
print(confusion_matrix(y_train, pred_dnn_train))
print ("Accuracy : training data")
print(accuracy_score(y_train,pred_dnn_train)*100)
print("Report : training data")
report = classification_report(y_train, pred_dnn_train)
print(report)

def getFeature(length,percent,incdec,paths):
    prepped_data = fullScript(length,percent,incdec,paths) 
    after_add_NX = make_data(prepped_data)
    return after_add_NX,prepped_data.iloc[:,1:7]

aapl_y,aapl_edited = getFeature(5,0.05,1,'aapl_edited.xlsx')
aapl_edited = aapl_edited[aapl_edited.index >= aapl_y.index[0]]
aapl_df = pd.read_excel('aapl_edited.xlsx', index_col=0,parse_dates=True)
pred_aapl = model.predict(aapl_edited).round()
print ("Accuracy aapl: ")
print(accuracy_score(aapl_y['N/X'],pred_aapl)*100)

goog_y,goog_edited = getFeature(5,0.05,1,'goog_edited.xlsx')
goog_edited = goog_edited[goog_edited.index >= goog_y.index[0]]
goog_df = pd.read_excel('goog_edited.xlsx', index_col=0,parse_dates=True)
pred_goog = model.predict(goog_edited).round()
print ("Accuracy goog: ")
print(accuracy_score(aapl_y['N/X'],pred_aapl)*100)
# goog_df = goog_df.dropna()
# goog_df['predicted'] = pred_goog
# goog_df.to_csv("goog_edited_predicted.csv", index_label="index_label")

msft_y,msft_edited = getFeature(5,0.05,1,'msft.edited.xlsx')
msft_edited = msft_edited[msft_edited.index >= msft_y.index[0]]
msft_df = pd.read_excel('msft.edited.xlsx', index_col=0,parse_dates=True)
pred_msft = model.predict(msft_edited).round()
print ("Accuracy msft: ")
print(accuracy_score(msft_y['N/X'],pred_msft)*100)

nvda_y,nvda_edited = getFeature(5,0.05,1,'nvda_edited.xlsx')
nvda_edited = nvda_edited[nvda_edited.index >= nvda_y.index[0]]
nvda_df = pd.read_excel('nvda_edited.xlsx', index_col=0,parse_dates=True)
pred_nvda = model.predict(nvda_edited).round()
print ("Accuracy nvda: ")
print(accuracy_score(nvda_y['N/X'],pred_nvda)*100)

tsla_y,tsla_edited = getFeature(5,0.05,1,'tsla_edited.xlsx')
tsla_edited = tsla_edited[tsla_edited.index >= nvda_y.index[0]]
tsla_df = pd.read_excel('tsla_edited.xlsx', index_col=0,parse_dates=True)
pred_tsla = model.predict(tsla_edited).round()
print ("Accuracy tsla: ")
print(accuracy_score(tsla_y['N/X'],pred_tsla)*100)

